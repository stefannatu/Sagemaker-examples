{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> PipeMode using Tensorflow Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PipeMode is a new feature for training large scale datasets in Sagemaker. Without having to load the data into the local machine, Sagemaker now allows training a model directly using data staged in S3. This is perfectly suited for data that doesn't fit in memory, and is built on top of Tensorflow's data.dataset API.\n",
    "\n",
    "The Legacy PipeMode will soon be deprecated, as there is a new script mode option which gives customers more flexibility to run their python scripts in pipe mode and build and bring their own models into pipe mode. This sample notebook and accompanying script file shows how to run Tensorflow Estimators with PipeMode in script mode.\n",
    "\n",
    "Sample data comes from MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "sagemaker_session = sagemaker.Session()\n",
    "import sagemaker\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket() # we are using a default bucket here but you can change it to any bucket in your account\n",
    "prefix = 'sagemaker/mnist-pipemode' # you can customize the prefix (subfolder) here\n",
    "\n",
    "role = sagemaker.get_execution_role() # we are using the notebook instance role for training in this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-389535300735/sagemaker/mnist-pipemode/customcode/tensorflow_pipemode\n"
     ]
    }
   ],
   "source": [
    "custom_code_upload_location = 's3://{}/{}/customcode/tensorflow_pipemode'.format(bucket, prefix)\n",
    "print(custom_code_upload_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker import tensorflow\n",
    "import utils_sharded\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-ac86a0aca712>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "data_sets = mnist.read_data_sets('data', dtype=tf.uint8, reshape=False, validation_size=5000, one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data/train/train-1.tfrecords\n",
      "Writing data/train/train-2.tfrecords\n",
      "Writing data/train/train-3.tfrecords\n",
      "Writing data/train/train-4.tfrecords\n",
      "Writing data/train/train-5.tfrecords\n",
      "Writing data/val/validation-1.tfrecords\n",
      "Writing data/val/validation-2.tfrecords\n",
      "Writing data/val/validation-3.tfrecords\n",
      "Writing data/val/validation-4.tfrecords\n",
      "Writing data/val/validation-5.tfrecords\n",
      "Writing data/test/test-1.tfrecords\n",
      "Writing data/test/test-2.tfrecords\n",
      "Writing data/test/test-3.tfrecords\n",
      "Writing data/test/test-4.tfrecords\n",
      "Writing data/test/test-5.tfrecords\n"
     ]
    }
   ],
   "source": [
    "utils_sharded.process_data(data_sets.train, 'train', 'data/train', num_shards=5)\n",
    "utils_sharded.process_data(data_sets.validation, 'validation', 'data/val',num_shards=5)\n",
    "utils_sharded.process_data(data_sets.test, 'test', 'data/test',num_shards=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-389535300735/sagemaker/mnist-pipemode/data/mnist\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker.Session().upload_data(path='data', bucket=bucket, key_prefix=prefix+'/data/mnist')\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m#!/usr/bin/env python3\u001b[39;49;00m\r\n",
      "\u001b[37m# -*- coding: utf-8 -*-\u001b[39;49;00m\r\n",
      "\u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33mCreated on Tue Jun  4 12:30:50 2019\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m@author: stenatu\u001b[39;49;00m\r\n",
      "\u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m#!/usr/bin/env python3\u001b[39;49;00m\r\n",
      "\u001b[37m# -*- coding: utf-8 -*-\u001b[39;49;00m\r\n",
      "\u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33mCreated on Thu May 30 14:31:44 2019\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m@author: stenatu\u001b[39;49;00m\r\n",
      "\u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m#!/usr/bin/env python3\u001b[39;49;00m\r\n",
      "\u001b[37m# -*- coding: utf-8 -*-\u001b[39;49;00m\r\n",
      "\u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33mCreated on Tue May 28 09:19:09 2019\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m@author: stenatu\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33mIn this code I show how to modify PipeMode dataset to work with script mode,\u001b[39;49;00m\r\n",
      "\u001b[33msince the py2 version of PipeMode (and all the notebook examples in the documentation)\u001b[39;49;00m\r\n",
      "\u001b[33mwill be deprecated shortly.\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_tensorflow\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m PipeModeDataset\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\r\n",
      "\r\n",
      "HEIGHT = \u001b[34m28\u001b[39;49;00m\r\n",
      "WIDTH = \u001b[34m28\u001b[39;49;00m\r\n",
      "DEPTH = \u001b[34m1\u001b[39;49;00m\r\n",
      "\r\n",
      "NUM_PARALLEL_BATCHES = \u001b[34m10\u001b[39;49;00m\r\n",
      "INPUT_TENSOR_NAME = \u001b[33m'\u001b[39;49;00m\u001b[33minputs_input\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "NCLASSES = \u001b[34m10\u001b[39;49;00m\u001b[37m# or num classes if problem is not binary classification\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# Optionally add configs for estimator function here\u001b[39;49;00m\r\n",
      "\u001b[37m#CHECKPOINT_STEPS = None\u001b[39;49;00m\r\n",
      "\u001b[37m# TO BE ADDED\u001b[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "logging.getLogger().setLevel(logging.INFO)\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mserving_input_fn\u001b[39;49;00m():\r\n",
      "    inputs = {INPUT_TENSOR_NAME: tf.placeholder(tf.float32, [\u001b[36mNone\u001b[39;49;00m, HEIGHT*WIDTH*DEPTH])}\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n",
      "\r\n",
      "\u001b[37m# Create training and eval input functions. \u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain_input_fn\u001b[39;49;00m(params):\r\n",
      "    \u001b[33m\"\"\"Returns input function that would feed the model during training\"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m read_dataset(\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, args.batch_size)\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32meval_input_fn\u001b[39;49;00m(params):\r\n",
      "    \u001b[33m\"\"\"Returns input function that would feed the model during evaluation\"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m read_dataset(\u001b[33m'\u001b[39;49;00m\u001b[33meval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, args.batch_size) \u001b[37m# set epochs to 1\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# Create a read dataset function which returns _input_fn. This is crucial \u001b[39;49;00m\r\n",
      "\u001b[37m# for canned estimators to make sure you don't get a \"Not Callable\" error.\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mread_dataset\u001b[39;49;00m(channel, batch_size):\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m_input_fn\u001b[39;49;00m():\r\n",
      "        \u001b[34mdef\u001b[39;49;00m \u001b[32m_read_and_decode\u001b[39;49;00m(record):\r\n",
      "            features = tf.parse_single_example(\r\n",
      "                    record,\r\n",
      "                    features={\r\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mimage_raw\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: tf.FixedLenFeature([], tf.string),\r\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: tf.FixedLenFeature([], tf.int64),\r\n",
      "                     })\r\n",
      "\r\n",
      "            image = tf.decode_raw(features[\u001b[33m'\u001b[39;49;00m\u001b[33mimage_raw\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], tf.uint8)\r\n",
      "            image.set_shape([HEIGHT*WIDTH*DEPTH])\r\n",
      "            image = tf.cast(image, tf.float32) * (\u001b[34m1.\u001b[39;49;00m / \u001b[34m255\u001b[39;49;00m)\r\n",
      "            label = tf.cast(features[\u001b[33m'\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], tf.int32)\r\n",
      "\r\n",
      "            \u001b[34mreturn\u001b[39;49;00m {INPUT_TENSOR_NAME: image}, label\r\n",
      "\r\n",
      "    \r\n",
      "        ds = PipeModeDataset(channel, record_format=\u001b[33m'\u001b[39;49;00m\u001b[33mTFRecord\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "        ds = ds.repeat()\r\n",
      "        ds = ds.prefetch(batch_size)\r\n",
      "        ds = ds.map(_read_and_decode, num_parallel_calls = NUM_PARALLEL_BATCHES)\r\n",
      "        \r\n",
      "        \u001b[34mif\u001b[39;49;00m channel == \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "            ds= ds.shuffle(buffer_size = batch_size)\r\n",
      "\r\n",
      "        ds = ds.batch(batch_size, drop_remainder = \u001b[36mTrue\u001b[39;49;00m)\r\n",
      "        ds = ds.make_one_shot_iterator().get_next()\r\n",
      "    \r\n",
      "        \u001b[34mreturn\u001b[39;49;00m ds\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m _input_fn\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m==\u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\u001b[37m#    # hyperparameters sent by the client are passed as command-line arguments to the script.\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_OUTPUT_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m = \u001b[36mstr\u001b[39;49;00m, default = os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m32\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--steps\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10000\u001b[39;49;00m) \u001b[37m# max_steps parameter for training\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--eval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_VAL\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "\r\n",
      "\r\n",
      "    args, _ = parser.parse_known_args()\r\n",
      "\u001b[37m#    \u001b[39;49;00m\r\n",
      "    logging.info(\u001b[33m'\u001b[39;49;00m\u001b[33mgetting data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\u001b[37m#    \u001b[39;49;00m\r\n",
      "    train_spec = tf.estimator.TrainSpec(train_input_fn(params = \u001b[36mNone\u001b[39;49;00m), max_steps = args.steps)\r\n",
      "\u001b[37m#    val_dataset = eval_input_fn(params = None)\u001b[39;49;00m\r\n",
      "    eval_spec = tf.estimator.EvalSpec(eval_input_fn(params = \u001b[36mNone\u001b[39;49;00m))\r\n",
      "\u001b[37m#    \u001b[39;49;00m\r\n",
      "\u001b[37m#    \u001b[39;49;00m\r\n",
      "    logging.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mBuilding Tensorflow Estimator model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "\r\n",
      "\u001b[37m#  specify features columns here. In this case we only have one, or else specify as a list. \u001b[39;49;00m\r\n",
      "    \r\n",
      "    column = [tf.feature_column.numeric_column(INPUT_TENSOR_NAME, shape=[HEIGHT*WIDTH*DEPTH])]\r\n",
      "    \r\n",
      "\u001b[37m# Build a simple linear classifier -- just change the code to whatever canned estimator you want to use.    \u001b[39;49;00m\r\n",
      "    estimator = tf.estimator.LinearClassifier(feature_columns=column, \r\n",
      "                                         model_dir = args.model_dir,\r\n",
      "                                         n_classes=NCLASSES,\r\n",
      "                                         config=\u001b[36mNone\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \r\n",
      "    logging.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mTrain and Evaluate model using TrainSpec, EvalSpec\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    tf.estimator.train_and_evaluate(estimator,train_spec, eval_spec)\r\n",
      " \r\n",
      "    \r\n",
      "    \u001b[37m#feature_spec = tf.feature_column.make_parse_example_spec(column)\u001b[39;49;00m\r\n",
      "    \u001b[37m#export_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\u001b[39;49;00m\r\n",
      "    estimator.export_savedmodel(export_dir_base = args.model_dir, \r\n",
      "                                assets_extra = \u001b[36mNone\u001b[39;49;00m,\r\n",
      "                                serving_input_receiver_fn = serving_input_fn, \r\n",
      "                                as_text=\u001b[36mFalse\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize pipemode_MNIST.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "#NUM_EPOCHS   = 5\n",
    "BATCH_SIZE   = 30\n",
    "#INPUT_MODE   = 'Pipe' # Can try it with 'File' mode as well\n",
    "#num_train_samples = 500 # replace with num data samples\n",
    "#num_val_samples = 500 \n",
    "#num_test_samples= 500\n",
    "STEPS = 1000\n",
    "\n",
    "hyperparameters = {'batch_size': BATCH_SIZE,\n",
    "                   'steps': STEPS,\n",
    "                    'model_dir': custom_code_upload_location}\n",
    "\n",
    "tensorflow = TensorFlow(entry_point='pipemode_MNIST.py',\n",
    "                        role = role,\n",
    "                        output_path = custom_code_upload_location,\n",
    "                        hyperparameters = hyperparameters,\n",
    "                        framework_version='1.12.0',\n",
    "                        py_version = 'py3',\n",
    "                        input_mode='Pipe',\n",
    "                        train_instance_count=1,\n",
    "                        train_instance_type='ml.c4.xlarge',\n",
    "                       script_mode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-04 21:52:38 Starting - Starting the training job...\n",
      "2019-06-04 21:52:41 Starting - Launching requested ML instances......\n",
      "2019-06-04 21:53:43 Starting - Preparing the instances for training...\n",
      "2019-06-04 21:54:39 Downloading - Downloading input data\n",
      "2019-06-04 21:54:39 Training - Training image download completed. Training in progress...\n",
      "\u001b[31m2019-06-04 21:54:42,886 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[31m2019-06-04 21:54:42,893 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-06-04 21:54:43,201 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-06-04 21:54:43,217 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-06-04 21:54:43,229 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"eval\": \"/opt/ml/input/data/eval\",\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 30,\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-2-389535300735/sagemaker/mnist-pipemode/customcode/tensorflow_pipemode/sagemaker-tensorflow-scriptmode-2019-06-04-21-52-37-575/model\",\n",
      "        \"steps\": 1000\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"eval\": {\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-tensorflow-scriptmode-2019-06-04-21-52-37-575\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-389535300735/sagemaker-tensorflow-scriptmode-2019-06-04-21-52-37-575/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"pipemode_MNIST\",\n",
      "    \"network_interface_name\": \"ethwe\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"ethwe\"\n",
      "    },\n",
      "    \"user_entry_point\": \"pipemode_MNIST.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=ethwe\u001b[0m\n",
      "\u001b[31mSM_HPS={\"batch_size\":30,\"model_dir\":\"s3://sagemaker-us-east-2-389535300735/sagemaker/mnist-pipemode/customcode/tensorflow_pipemode/sagemaker-tensorflow-scriptmode-2019-06-04-21-52-37-575/model\",\"steps\":1000}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=pipemode_MNIST.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"eval\",\"test\",\"train\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=pipemode_MNIST\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-us-east-2-389535300735/sagemaker-tensorflow-scriptmode-2019-06-04-21-52-37-575/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"eval\":\"/opt/ml/input/data/eval\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":30,\"model_dir\":\"s3://sagemaker-us-east-2-389535300735/sagemaker/mnist-pipemode/customcode/tensorflow_pipemode/sagemaker-tensorflow-scriptmode-2019-06-04-21-52-37-575/model\",\"steps\":1000},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-tensorflow-scriptmode-2019-06-04-21-52-37-575\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-389535300735/sagemaker-tensorflow-scriptmode-2019-06-04-21-52-37-575/source/sourcedir.tar.gz\",\"module_name\":\"pipemode_MNIST\",\"network_interface_name\":\"ethwe\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"},\"user_entry_point\":\"pipemode_MNIST.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--batch_size\",\"30\",\"--model_dir\",\"s3://sagemaker-us-east-2-389535300735/sagemaker/mnist-pipemode/customcode/tensorflow_pipemode/sagemaker-tensorflow-scriptmode-2019-06-04-21-52-37-575/model\",\"--steps\",\"1000\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_EVAL=/opt/ml/input/data/eval\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_HP_BATCH_SIZE=30\u001b[0m\n",
      "\u001b[31mSM_HP_MODEL_DIR=s3://sagemaker-us-east-2-389535300735/sagemaker/mnist-pipemode/customcode/tensorflow_pipemode/sagemaker-tensorflow-scriptmode-2019-06-04-21-52-37-575/model\u001b[0m\n",
      "\u001b[31mSM_HP_STEPS=1000\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python pipemode_MNIST.py --batch_size 30 --model_dir s3://sagemaker-us-east-2-389535300735/sagemaker/mnist-pipemode/customcode/tensorflow_pipemode/sagemaker-tensorflow-scriptmode-2019-06-04-21-52-37-575/model --steps 1000\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mINFO:root:getting data\u001b[0m\n",
      "\u001b[31mINFO:root:Building Tensorflow Estimator model\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Using default config.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Using default config.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Using config: {'_model_dir': '/opt/ml/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\u001b[0m\n",
      "\u001b[31mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[31m}\u001b[0m\n",
      "\u001b[31m, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0631b0a358>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Using config: {'_model_dir': '/opt/ml/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\u001b[0m\n",
      "\u001b[31mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[31m}\u001b[0m\n",
      "\u001b[31m, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0631b0a358>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[31mINFO:root:Train and Evaluate model using TrainSpec, EvalSpec\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Running training and evaluation locally (non-distributed).\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Running training and evaluation locally (non-distributed).\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Saving checkpoints for 0 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Saving checkpoints for 0 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 69.07755, step = 1\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 69.07755, step = 1\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 434.119\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 434.119\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 14.179945, step = 101 (0.231 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 14.179945, step = 101 (0.231 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 533.661\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 533.661\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 10.067008, step = 201 (0.187 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 10.067008, step = 201 (0.187 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 513.828\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 513.828\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 9.233166, step = 301 (0.195 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 9.233166, step = 301 (0.195 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 476.669\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 476.669\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 21.917799, step = 401 (0.210 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 21.917799, step = 401 (0.210 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 498.579\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 498.579\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 11.243076, step = 501 (0.201 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 11.243076, step = 501 (0.201 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 433.367\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 433.367\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 10.046547, step = 601 (0.231 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 10.046547, step = 601 (0.231 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 546.583\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 546.583\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 11.084055, step = 701 (0.183 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 11.084055, step = 701 (0.183 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 523.755\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 523.755\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 2.2652426, step = 801 (0.191 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 2.2652426, step = 801 (0.191 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 537.923\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 537.923\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 16.200329, step = 901 (0.186 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 16.200329, step = 901 (0.186 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Saving checkpoints for 1000 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Saving checkpoints for 1000 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Starting evaluation at 2019-06-04-21:54:47\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Starting evaluation at 2019-06-04-21:54:47\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-1000\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-1000\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [10/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [10/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [20/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [20/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [30/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [30/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [40/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [40/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [50/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [50/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [60/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [60/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [70/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [70/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [80/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [80/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [90/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [90/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [100/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [100/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Finished evaluation at 2019-06-04-21:54:47\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Finished evaluation at 2019-06-04-21:54:47\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Saving dict for global step 1000: accuracy = 0.91433334, average_loss = 0.3121945, global_step = 1000, loss = 9.365835\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Saving dict for global step 1000: accuracy = 0.91433334, average_loss = 0.3121945, global_step = 1000, loss = 9.365835\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /opt/ml/model/model.ckpt-1000\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /opt/ml/model/model.ckpt-1000\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Loss for final step: 6.333711.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Loss for final step: 6.333711.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'inputs_input': <tf.Tensor 'Placeholder_1:0' shape=(?, 784) dtype=float32>}\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'inputs_input': <tf.Tensor 'Placeholder_1:0' shape=(?, 784) dtype=float32>}\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'inputs_input': <tf.Tensor 'Placeholder_1:0' shape=(?, 784) dtype=float32>}\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'inputs_input': <tf.Tensor 'Placeholder_1:0' shape=(?, 784) dtype=float32>}\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:Export includes no default signature!\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:Export includes no default signature!\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-1000\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-1000\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py:1046: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mPass your op to the equivalent parameter main_op instead.\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py:1046: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mPass your op to the equivalent parameter main_op instead.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Assets added to graph.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Assets added to graph.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:No assets to write.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:No assets to write.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:SavedModel written to: /opt/ml/model/temp-b'1559685287'/saved_model.pb\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:SavedModel written to: /opt/ml/model/temp-b'1559685287'/saved_model.pb\u001b[0m\n",
      "\u001b[31m2019-06-04 21:54:48,535 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-06-04 21:54:55 Uploading - Uploading generated training model\n",
      "2019-06-04 21:54:55 Completed - Training job completed\n",
      "Billable seconds: 38\n",
      "CPU times: user 379 ms, sys: 17.7 ms, total: 397 ms\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "\n",
    "\n",
    "# use the region-specific sample data bucket\n",
    "remote_inputs = {'train' : inputs + '/train', \n",
    "                 'eval'   : inputs +'/val', \n",
    "                 'test'  : inputs +'/test'}\n",
    "tensorflow.fit(remote_inputs, wait=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that although trainig is completed, script mode does not automatically save model files to opt/ml/model for tensorflow estimators. In order to get it to work you have to do 2 things --\n",
    "modify model_dir in your estimator and a .export_saved_model command with model_dir specified to the default value (opt/ml/model)\n",
    "\n",
    "If you follow these steps, then deploy should work in estimator mode as shown below. Also your model tar file should be in the custom location where you want it to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.72 µs\n",
      "---------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "%time\n",
    "predictor = tensorflow.deploy(initial_instance_count=1,\n",
    "                             instance_type='ml.c4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction with an unseen test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from model with message \"{ \"error\": \"Serving signature name: \\\"serving_default\\\" not found in signature def\" }\". See https://us-east-2.console.aws.amazon.com/cloudwatch/home?region=us-east-2#logEventViewer:group=/aws/sagemaker/Endpoints/sagemaker-tensorflow-serving-2019-06-04-22-22-25-787 in account 389535300735 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-79e84b10b439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_to_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHEIGHT\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mWIDTH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpredicted_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/tensorflow/serving.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CustomAttributes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mrequest_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_request_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from model with message \"{ \"error\": \"Serving signature name: \\\"serving_default\\\" not found in signature def\" }\". See https://us-east-2.console.aws.amazon.com/cloudwatch/home?region=us-east-2#logEventViewer:group=/aws/sagemaker/Endpoints/sagemaker-tensorflow-serving-2019-06-04-22-22-25-787 in account 389535300735 for more information."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "total_to_test = 100 # or to use the whole test suite, set this to: len(X_test)\n",
    "num_accurate  = 0\n",
    "HEIGHT = 28\n",
    "WIDTH = 28\n",
    "\n",
    "for i in range(total_to_test):\n",
    "    result = predictor.predict(np.reshape(data_sets.test.images[i], [-1, HEIGHT*WIDTH]))\n",
    "    predicted_prob = result['predictions'][0][0]\n",
    "    predicted_label = round(predicted_prob)\n",
    "    if y_test[i] == predicted_label:\n",
    "        num_accurate += 1\n",
    "        print('PASS. Actual: {:.0f}, Prob: {:.4f}'.format(y_test[i], predicted_prob))\n",
    "    else:\n",
    "        print('FAIL. Actual: {:.0f}, Prob: {:.4f}'.format(y_test[i], predicted_prob))\n",
    "print('Acc: {:.2%}'.format(num_accurate/total_to_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete endpoint when done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all data from S3 when done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('data', ignore_errors=True)\n",
    "s3 = boto3.resource('s3')\n",
    "s3_bucket = s3.Bucket(bucket)\n",
    "resp = s3_bucket.objects.filter(Prefix=data_prefix + '/').delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
